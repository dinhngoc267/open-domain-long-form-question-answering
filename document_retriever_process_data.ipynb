{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "document retriever_process data.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d306bbd4c85643ab9c990587743a9f34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4645fd2a997f4ffa8338251322c5b2f2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c514c991fb3542259c8ab979330738ed",
              "IPY_MODEL_ae76f8262b024ca3838b45101356d7f5",
              "IPY_MODEL_07cc607442254535bc6d9ebf7be64283"
            ]
          }
        },
        "4645fd2a997f4ffa8338251322c5b2f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c514c991fb3542259c8ab979330738ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_45c6479ba7484f2984e5517893a8b698",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_be48dd5477d149298dd94d6d1b0b52cf"
          }
        },
        "ae76f8262b024ca3838b45101356d7f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0c2d894eb6b34b5fbaf1bd383a19884b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 483,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 483,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_34ed4c7b784445318fdffa919b3a3433"
          }
        },
        "07cc607442254535bc6d9ebf7be64283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_10b5cf3e7ff3401b95c52ef4eae6e3d7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 483/483 [00:00&lt;00:00, 10.3kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5b5935405e27416aa2846c64f42b7aa8"
          }
        },
        "45c6479ba7484f2984e5517893a8b698": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "be48dd5477d149298dd94d6d1b0b52cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c2d894eb6b34b5fbaf1bd383a19884b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "34ed4c7b784445318fdffa919b3a3433": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "10b5cf3e7ff3401b95c52ef4eae6e3d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5b5935405e27416aa2846c64f42b7aa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "98ee98de13cf4b3db444eebe2752f14a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_85ac93da8f3a43858caef94ca2205847",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2d7fb48046de403394708f31e0783fc7",
              "IPY_MODEL_ee29dad19df045eda8e77aa356ca99e3",
              "IPY_MODEL_bca9551a825a47399e949e948725053d"
            ]
          }
        },
        "85ac93da8f3a43858caef94ca2205847": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2d7fb48046de403394708f31e0783fc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d67ebaab058a4123879de4b39064d6e3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f5b293f4a49542f89eab9a4f145ca6d6"
          }
        },
        "ee29dad19df045eda8e77aa356ca99e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_957af17b3ac2448eb8bc77fbb668b0ee",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 363423424,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 363423424,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_adbc72209e1146af8f0a5f8633025875"
          }
        },
        "bca9551a825a47399e949e948725053d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d298c9bdba644e2a9f73f9cbadac47c2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 347M/347M [00:12&lt;00:00, 29.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9c785fde2e154eb28a9fdde77d2a2a9e"
          }
        },
        "d67ebaab058a4123879de4b39064d6e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f5b293f4a49542f89eab9a4f145ca6d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "957af17b3ac2448eb8bc77fbb668b0ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "adbc72209e1146af8f0a5f8633025875": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d298c9bdba644e2a9f73f9cbadac47c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9c785fde2e154eb28a9fdde77d2a2a9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWCUYNOC7xSH"
      },
      "source": [
        "## Get the answer by google search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m18s6GAbk-Qa",
        "outputId": "2743e126-6abe-42ea-a360-03da3a8574e0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMo073RhIy4v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5975f685-4e4d-4bbb-8370-dbf789ad85da"
      },
      "source": [
        "!pip install -qq transformers\n",
        "!pip install -qq nlp"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.9 MB 5.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 36.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 36.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 636 kB 47.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 5.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 243 kB 42.6 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiRimxQN8Mbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "72285b1c-15ec-43c8-e221-e35d65115773"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import transformers\n",
        "from tqdm import tqdm\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow as tf\n",
        "from keras.layers import Lambda\n",
        "import nlp\n",
        "import keras\n",
        "import string\n",
        "import math\n",
        "import random\n",
        "\n",
        "eli5 = nlp.load_dataset('eli5')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ffb55317a224763bd22161e5efdbd1b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/17.8k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f4957a70f5c4c15bff0b5899660c863",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/3.71k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset eli5/LFQA_reddit (download: 6.03 MiB, generated: 1.26 GiB, post-processed: Unknown sizetotal: 1.26 GiB) to /root/.cache/huggingface/datasets/eli5/LFQA_reddit/1.0.0/58e61a99404336f0891b4457a02232489b50131bdca9c1691054aeee2f6f1a6e...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "602747ff869248049ceab22d434d48c1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/3.50k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f59d0b7a746544f997759f405f149b59",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/576M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad767e3c457d4dc1a1bb8a821f86725d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/21.1M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99d93afa73634cdeb15aa4025f5f28eb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/53.0M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52548662b4524d2c82cf1925acf9c2c4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/286M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2ffbf4e2d7d423b9c60cc6706859b22",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/9.65M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3f4585d885643c082026c4dcf95a605",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/17.7M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "312e1ce1395a4a32bbc809b0462e2c37",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/330M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0725445fdbc434dbc9e786769bc6abc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/18.7M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "199037cc8ba94cc287a7c9814c2c18a1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/36.2M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset eli5 downloaded and prepared to /root/.cache/huggingface/datasets/eli5/LFQA_reddit/1.0.0/58e61a99404336f0891b4457a02232489b50131bdca9c1691054aeee2f6f1a6e. Subsequent calls will reuse this data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_oLPhxG4tzW"
      },
      "source": [
        "#### Handle Eli5 dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sB6kpk05Sub"
      },
      "source": [
        "> After observing: There are some answers are not relevant to the questions and there are some questions are too short (one or two words)\n",
        "\n",
        "> I just get the questions which have more than two words\n",
        "> Just get maximum 2 answers with highest score each question.\n",
        "> Just get answer which more than 6 words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsQbwwBiPGAt"
      },
      "source": [
        "> After cleaning and check validation\n",
        "\n",
        "- Number of all questions: 263186\n",
        "- Number of all answes: 425285\n",
        "- Number of training questions: 688469\n",
        "- Number of training answers: 688469\n",
        "\n",
        "> Too large to train. It takes 6-7 hours per epoch\n",
        "\n",
        "> I cut off to 200,000 questions by random sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AzIdsHN6xPt"
      },
      "source": [
        "def is_valid_question(text):\n",
        "  if len(text.split()) > 3:\n",
        "    return True  \n",
        "  if len(text.split()) == 3:\n",
        "    if ('?' in text) or (text[0].lower() in ['w', 'h', 'i', 'a', 'd']):\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "def is_valid_answer(text):\n",
        "  if len(text.split()) > 8:\n",
        "    return True\n",
        "  return False\n",
        "\n",
        "def clean_text(text):\n",
        "  text = text.replace(\"\\n\",\"\")\n",
        "  text = ' '.join([x for x in text.split() if x != \"\" and x not in string.punctuation and \"URL\" not in x and \"@\" not in x and \"www\" not in x])\n",
        "  return text"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJMWE8jK-U0s"
      },
      "source": [
        "def create_eli5_q_a_dict(data, n_samples = None):\n",
        "  list_dict = []\n",
        "\n",
        "  for idx in tqdm(range(len(data))):\n",
        "    item = data[idx]\n",
        "    q_a = {}\n",
        "    \n",
        "    q_a['question'] = clean_text(item['title'])\n",
        "    if is_valid_question(q_a['question']) == False:\n",
        "      continue\n",
        "    \n",
        "    q_a['answers'] = []\n",
        "\n",
        "    for ans in item['answers']['text']:\n",
        "      tmp = clean_text(ans)\n",
        "      if is_valid_answer(tmp) == True:\n",
        "        q_a['answers'].append(tmp)\n",
        "        if len(q_a['answers']) == 2:\n",
        "          break\n",
        "\n",
        "    if len(q_a['answers']) > 0:\n",
        "      list_dict.append(q_a)\n",
        "\n",
        "  if n_samples is not None:\n",
        "    shuffle_indices = random.sample(range(len(list_dict)), n_samples)\n",
        "    list_dict = np.array(list_dict)\n",
        "    list_dict = list_dict[shuffle_indices]\n",
        "\n",
        "  return list_dict"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rK_khs9x_Cce",
        "outputId": "bf734f2d-2411-461c-cd4a-a4153e411d95"
      },
      "source": [
        "eli5_q_a_training_dict = create_eli5_q_a_dict(eli5['train_eli5'], n_samples=200000)\n",
        "eli5_q_a_valid_dict = create_eli5_q_a_dict(eli5['validation_eli5'])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 272634/272634 [01:12<00:00, 3784.29it/s]\n",
            "100%|██████████| 9812/9812 [00:02<00:00, 3801.11it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Y0mj2QFp_gi"
      },
      "source": [
        "#### Handle FQA Covid 19 dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7qQToCeqJTM"
      },
      "source": [
        "import pandas as pd\n",
        "covid19_df1 = pd.read_csv(\"/content/drive/MyDrive/FAQ_Bank.csv\")\n",
        "covid19_df1.dropna(inplace=True)\n",
        "\n",
        "covid19_questions_data1 = covid19_df1[covid19_df1['language'] == 'en']['question'].apply(lambda x: clean_text(x))\n",
        "covid19_answers_data1 = covid19_df1[covid19_df1['language'] == 'en']['answer'].apply(lambda x: clean_text(x))\n",
        "covid19_questions_data1 = covid19_questions_data1.values\n",
        "covid19_answers_data1 = covid19_answers_data1.values\n",
        "\n",
        "covid19_df2 = pd.read_csv(\"/content/drive/MyDrive/faq_covidbert.csv\")\n",
        "\n",
        "covid19_questions_data2 = covid19_df2[covid19_df2['lang']=='en']['question'].apply(lambda x: clean_text(x))\n",
        "covid19_answers_data2 = covid19_df2[covid19_df2['lang']=='en']['answer'].apply(lambda x: clean_text(x))\n",
        "covid19_questions_data2 = covid19_questions_data2.values\n",
        "covid19_answers_data2 = covid19_answers_data2.values\n",
        "\n",
        "covid19_questions = np.concatenate([covid19_questions_data1, covid19_questions_data2])\n",
        "covid19_answers = np.concatenate([covid19_answers_data1, covid19_answers_data2])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_ChkasqF3OA"
      },
      "source": [
        "n_samples = len(covid19_questions)\n",
        "shuffle_indices = random.sample(range(n_samples), n_samples)\n",
        "\n",
        "covid19_questions = covid19_questions[shuffle_indices]\n",
        "covid19_answers = covid19_answers[shuffle_indices]\n",
        "\n",
        "covid19_train_questions = covid19_questions[:8000]\n",
        "covid19_train_anwers = covid19_answers[:8000]\n",
        "\n",
        "covid19_vali_questions = covid19_questions[8000:]\n",
        "covid19_valid_answes = covid19_answers[8000:]"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBZrifjgEOR-"
      },
      "source": [
        "def create_covid19_q_a_dict(covid19_questions, covid19_answers):\n",
        "  list_dict = []\n",
        "\n",
        "  for idx in range(len(covid19_questions)):\n",
        "    q_a_dict = {}\n",
        "    q_a_dict['question'] = covid19_questions[idx]\n",
        "    q_a_dict['answers'] = [covid19_answers[idx]]\n",
        "\n",
        "    list_dict.append(q_a_dict)\n",
        "  \n",
        "  return np.array(list_dict)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqPpLV6KFKF_",
        "outputId": "1c060d48-e843-4d70-a1aa-6a665828ea6c"
      },
      "source": [
        "covid19_train_q_a_dict = create_covid19_q_a_dict(covid19_train_questions, covid19_train_anwers)\n",
        "covid19_valid_q_a_dict = create_covid19_q_a_dict(covid19_vali_questions, covid19_valid_answes)\n",
        "print('Number of questions in train set:', len(covid19_train_q_a_dict))\n",
        "print('Number of questions in valid set:', len(covid19_valid_q_a_dict))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of questions in train set: 8000\n",
            "Number of questions in valid set: 1362\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6yB7CXgH6QC"
      },
      "source": [
        "#### Combine two datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4at2EgIH99K",
        "outputId": "09110030-7f38-48fc-9463-fca4227f588f"
      },
      "source": [
        "q_a_training_dict = np.concatenate([eli5_q_a_training_dict, covid19_train_q_a_dict])\n",
        "q_a_valid_dict = np.concatenate([eli5_q_a_valid_dict, covid19_valid_q_a_dict])\n",
        "\n",
        "# after concat, shuffle data:\n",
        "\n",
        "n_samples = len(q_a_training_dict)\n",
        "shuffle_indices = random.sample(range(n_samples), n_samples)\n",
        "q_a_training_dict = q_a_training_dict[shuffle_indices]\n",
        "\n",
        "n_samples = len(q_a_valid_dict)\n",
        "shuffle_indices = random.sample(range(n_samples), n_samples)\n",
        "q_a_valid_dict = q_a_valid_dict[shuffle_indices]\n",
        "\n",
        "print('Length of training dict', len(q_a_training_dict))\n",
        "print('Length of valid dict', len(q_a_valid_dict))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of training dict 208000\n",
            "Length of valid dict 10934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-lSavu4I0ja"
      },
      "source": [
        "def create_all_training_q_a_list(data): \n",
        "  all_questions = []\n",
        "  all_answers = []\n",
        "  answer_question_mapping_index = []\n",
        "\n",
        "  for idx in tqdm(range(len(data))):\n",
        "    item = data[idx]\n",
        "    \n",
        "    all_questions.append(item['question'])  \n",
        "    for ans in item['answers']:\n",
        "      all_answers.append(ans)\n",
        "      answer_question_mapping_index.append(idx)\n",
        "\n",
        "  return all_questions, all_answers, answer_question_mapping_index\n",
        "\n",
        "def create_pairs_dataset(data):\n",
        "  questions = []\n",
        "  answers = []\n",
        "\n",
        "  # 1: positive, 0: negative\n",
        "  labels = []\n",
        "\n",
        "  for idx in tqdm(range(len(data))):\n",
        "    item = data[idx]\n",
        "    for ans in item['answers']:\n",
        "      questions.append(item['question'])\n",
        "      answers.append(ans)\n",
        "      labels.append(1)\n",
        "    \n",
        "    neg_idx = np.random.randint(0, len(data),1)[0]\n",
        "    if neg_idx != idx:\n",
        "      questions.append(item['question'])\n",
        "      answers.append(data[neg_idx]['answers'][0])\n",
        "      labels.append(0)\n",
        "\n",
        "  return questions, answers, labels"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_8h_4PlJs28",
        "outputId": "c53004c8-dc07-476d-c075-6f67dee52ca5"
      },
      "source": [
        "all_questions, all_answers, answer_question_mapping_index = create_all_training_q_a_list(q_a_training_dict)\n",
        "train_questions, train_answers, train_labels = create_pairs_dataset(q_a_training_dict)\n",
        "valid_questions, valid_answers, valid_labels = create_pairs_dataset(q_a_valid_dict)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 208000/208000 [00:00<00:00, 563010.18it/s]\n",
            "100%|██████████| 208000/208000 [00:07<00:00, 26020.75it/s]\n",
            "100%|██████████| 10934/10934 [00:00<00:00, 33447.20it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSSVAQQPJcfz",
        "outputId": "5752e395-e5aa-4779-bdf0-becf105e5573"
      },
      "source": [
        "print('Number of all questions:',len(all_questions))\n",
        "print('Number of all answes:',len(all_answers))\n",
        "print('Number of training questions:', len(train_questions))\n",
        "print('Number of training answers:', len(train_answers))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of all questions: 208000\n",
            "Number of all answes: 331119\n",
            "Number of training questions: 539119\n",
            "Number of training answers: 539119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHmhsgxVqNOH"
      },
      "source": [
        "train_labels = np.array(train_labels)\n",
        "valid_labels = np.array(valid_labels)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282,
          "referenced_widgets": [
            "d306bbd4c85643ab9c990587743a9f34",
            "4645fd2a997f4ffa8338251322c5b2f2",
            "c514c991fb3542259c8ab979330738ed",
            "ae76f8262b024ca3838b45101356d7f5",
            "07cc607442254535bc6d9ebf7be64283",
            "45c6479ba7484f2984e5517893a8b698",
            "be48dd5477d149298dd94d6d1b0b52cf",
            "0c2d894eb6b34b5fbaf1bd383a19884b",
            "34ed4c7b784445318fdffa919b3a3433",
            "10b5cf3e7ff3401b95c52ef4eae6e3d7",
            "5b5935405e27416aa2846c64f42b7aa8",
            "98ee98de13cf4b3db444eebe2752f14a",
            "85ac93da8f3a43858caef94ca2205847",
            "2d7fb48046de403394708f31e0783fc7",
            "ee29dad19df045eda8e77aa356ca99e3",
            "bca9551a825a47399e949e948725053d",
            "d67ebaab058a4123879de4b39064d6e3",
            "f5b293f4a49542f89eab9a4f145ca6d6",
            "957af17b3ac2448eb8bc77fbb668b0ee",
            "adbc72209e1146af8f0a5f8633025875",
            "d298c9bdba644e2a9f73f9cbadac47c2",
            "9c785fde2e154eb28a9fdde77d2a2a9e"
          ]
        },
        "id": "yJiOy7RaH0qf",
        "outputId": "587c67dc-e70c-4673-f1ac-b84d4698b341"
      },
      "source": [
        "transformer_layer = transformers.TFDistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d306bbd4c85643ab9c990587743a9f34",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98ee98de13cf4b3db444eebe2752f14a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/347M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['activation_13', 'vocab_layer_norm', 'vocab_transform', 'vocab_projector']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc0da88235d045298ff24b45777e2087",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d6a4fb0c358471e94411472880c5831",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13640c942839428c8928f97bede61bd1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dPSiFMRDPYf"
      },
      "source": [
        "def bert_encode(texts, tokenizer, max_len=512):\n",
        "  all_tokens = []\n",
        "\n",
        "  for idx in tqdm(range(len(texts))):\n",
        "    text = texts[idx]\n",
        "\n",
        "    text = ' '.join([x for x in text.split()[:100]])\n",
        "    text = tokenizer.tokenize(text)\n",
        "    text = text[:max_len-2]\n",
        "    input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
        "\n",
        "    pad_len = max_len - len(input_sequence)\n",
        "    tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
        "    tokens += [0]*pad_len\n",
        "    all_tokens.append(tokens)\n",
        "\n",
        "  return np.array(all_tokens)\n",
        "\n",
        "def build_siamese_model(transformer, max_len=512, embedding_dims = 128):\n",
        "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "    sequence_output = transformer(input_word_ids)[0]\n",
        "\n",
        "    #cls_token = sequence_output[:, 0, :]\n",
        "    out = tf.reduce_mean(sequence_output, axis=1)\n",
        "    out = Dense(128, activation = 'relu')(out)\n",
        "    \n",
        "    model = Model(inputs=input_word_ids, outputs=out)    \n",
        "    return model"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INRyjWYrWj6U",
        "outputId": "de4bce50-44af-464d-9a2f-82895ebd73bd"
      },
      "source": [
        "train_questions_tokens = bert_encode(train_questions, tokenizer, max_len=100)\n",
        "train_answers_tokens = bert_encode(train_answers, tokenizer, max_len=100)\n",
        "\n",
        "valid_questions_tokens = bert_encode(valid_questions, tokenizer, max_len=100)\n",
        "valid_answers_tokens = bert_encode(valid_answers, tokenizer, max_len=100)\n",
        "\n",
        "all_questions_tokens = bert_encode(all_questions, tokenizer, max_len=100)\n",
        "all_answers_tokens = bert_encode(all_answers, tokenizer, max_len=100)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 539119/539119 [05:03<00:00, 1777.75it/s]\n",
            "100%|██████████| 539119/539119 [20:26<00:00, 439.48it/s]\n",
            "100%|██████████| 27845/27845 [00:16<00:00, 1646.29it/s]\n",
            "100%|██████████| 27845/27845 [01:01<00:00, 449.74it/s]\n",
            "100%|██████████| 208000/208000 [01:54<00:00, 1821.38it/s]\n",
            "100%|██████████| 331119/331119 [12:22<00:00, 445.73it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AoLA2AVj0fO"
      },
      "source": [
        "np.save(\"/content/drive/MyDrive/train_questions_tokens.npy\", train_questions_tokens)\n",
        "np.save(\"/content/drive/MyDrive/train_answers_tokens.npy\", train_answers_tokens)\n",
        "np.save(\"/content/drive/MyDrive/valid_questions_tokens.npy\", valid_questions_tokens)\n",
        "np.save(\"/content/drive/MyDrive/valid_answers_tokens.npy\", valid_answers_tokens)\n",
        "np.save(\"/content/drive/MyDrive/all_questions_tokens.npy\", all_questions_tokens)\n",
        "np.save(\"/content/drive/MyDrive/all_answers_tokens.npy\", all_answers_tokens)\n",
        "np.save(\"/content/drive/MyDrive/train_labels.npy\", train_labels)\n",
        "np.save(\"/content/drive/MyDrive/valid_labels.npy\", valid_labels)\n",
        "np.save(\"/content/drive/MyDrive/answer_question_mapping_index.npy\", answer_question_mapping_index)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlDi9RlMzeLq"
      },
      "source": [
        "train_questions_tokens = np.load(\"/content/drive/MyDrive/train_questions_tokens.npy\")\n",
        "train_answers_tokens = np.load(\"/content/drive/MyDrive/train_answers_tokens.npy\")\n",
        "valid_questions_tokens = np.load(\"/content/drive/MyDrive/valid_questions_tokens.npy\")\n",
        "valid_answers_tokens = np.load(\"/content/drive/MyDrive/valid_answers_tokens.npy\")\n",
        "all_questions_tokens = np.load(\"/content/drive/MyDrive/all_questions_tokens.npy\")\n",
        "all_answers_tokens = np.load(\"/content/drive/MyDrive/all_answers_tokens.npy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9dn0ZUPPpJU"
      },
      "source": [
        "shuffle_indices = random.sample(range(1000), 1000)\n",
        "train_answers_tokens = train_answers_tokens[shuffle_indices]\n",
        "train_questions_tokens = train_questions_tokens[shuffle_indices]\n",
        "labels = labels[shuffle_indices] \n",
        "answer_question_mapping_index = np.array(answer_question_mapping_index[:1000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZKyHDVza5yL"
      },
      "source": [
        "class HardNegativeMiningCallback(keras.callbacks.Callback):\n",
        "  def __init__(self, all_question_tokens, all_answer_tokens, answer_question_mapping_index):\n",
        "    self.all_question_tokens = all_question_tokens\n",
        "    self.all_answer_tokens = all_answer_tokens\n",
        "    self.answer_question_mapping_index = np.array(answer_question_mapping_index)\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    if epoch == 1:\n",
        "      question_embeddings = self.model.layers[2].predict(self.all_question_tokens)\n",
        "      answer_embeddings = self.model.layers[2].predict(self.all_answer_tokens)\n",
        "\n",
        "      dist_matrix = tf.reduce_sum((tf.expand_dims(answer_embeddings[:100], 1)-tf.expand_dims(question_embeddings, 0))**2,2)\n",
        "\n",
        "      for i in tqdm(range(100, answer_embeddings.shape[0], 100)):\n",
        "        tmp = tf.reduce_sum((tf.expand_dims(answer_embeddings[i:i+100], 1)-tf.expand_dims(question_embeddings, 0))**2,2)\n",
        "        dist_matrix = tf.concat([dist_matrix, tmp], axis=0)\n",
        "\n",
        "      min_dist_indices = keras.backend.eval(tf.argmin(dist_matrix, axis=1))\n",
        "\n",
        "      hard_negative_indices = (min_dist_indices != self.answer_question_mapping_index).nonzero()[0]\n",
        "      hard_negative_pairs = [[i, min_dist_indices[i]] for i in hard_negative_indices]\n",
        "      hard_negative_pairs = np.array(hard_negative_pairs)\n",
        "\n",
        "      print('\\nFound: {} hard negative pairs'.format(len(hard_negative_pairs)))\n",
        "\n",
        "      hard_negative_question_tokens = self.all_question_tokens[hard_negative_pairs[:,1]]\n",
        "      hard_negative_answer_tokens = self.all_answer_tokens[hard_negative_pairs[:,0]]\n",
        "\n",
        "      global train_questions_tokens\n",
        "      global train_answers_tokens\n",
        "      global labels\n",
        "      train_questions_tokens = np.concatenate([train_questions_tokens, hard_negative_question_tokens], axis=0)\n",
        "      train_answers_tokens = np.concatenate([train_answers_tokens, hard_negative_answer_tokens], axis=0)\n",
        "      labels = np.concatenate([labels, np.zeros(shape=(len(hard_negative_pairs)))])\n",
        "\n",
        "      shuffle_indices = random.sample(range(len(labels)), len(labels))\n",
        "      train_answers_tokens = train_answers_tokens[shuffle_indices]\n",
        "      train_questions_tokens = train_questions_tokens[shuffle_indices]\n",
        "      labels = labels[shuffle_indices] \n",
        "\n",
        "      print('Train on {} samples'.format(len(train_questions_tokens)))\n",
        "\n",
        "class DistilBertRetriever():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  \n",
        "  def euclidean_distance(self, vectors):\n",
        "    featsA, featsB = vectors\n",
        "    # compute the sum of squared distances between the vectors\n",
        "    sumSquared = K.sum(K.square(featsA - featsB), axis=1,keepdims=True)\n",
        "    # return the euclidean distance between the vectors\n",
        "    return K.sqrt(K.maximum(sumSquared, K.epsilon()))\n",
        "\n",
        "  def contrastive_loss(self, y, preds, margin=1):\n",
        "    # explicitly cast the true class label data type to the predicted\n",
        "    # class label data type (otherwise we run the risk of having two\n",
        "    # separate data types, causing TensorFlow to error out)\n",
        "    y = tf.cast(y, preds.dtype)\n",
        "    # calculate the contrastive loss between the true labels and\n",
        "    # the predicted labels\n",
        "    squaredPreds = K.square(preds)\n",
        "    squaredMargin = K.square(K.maximum(margin - preds, 0))\n",
        "    loss = K.mean(y * squaredPreds + (1 - y) * squaredMargin)\n",
        "    # return the computed contrastive loss to the calling function\n",
        "    return loss\n",
        "\n",
        "  def build(self):\n",
        "    A = Input(shape=100)\n",
        "    B = Input(shape=100)\n",
        "    featureExtractor = build_siamese_model(transformer_layer, max_len=100)\n",
        "    featsA = featureExtractor(A)\n",
        "    featsB = featureExtractor(B)\n",
        "    # finally, construct the siamese network\n",
        "    distance = Lambda(self.euclidean_distance)([featsA, featsB])\n",
        "    model = Model(inputs=[A, B], outputs=distance)\n",
        "    model.compile(loss=self.contrastive_loss, optimizer=Adam(learning_rate=0.0001))\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufox5YQMjB6O"
      },
      "source": [
        "### Using cls token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xd62jl5-B7u7"
      },
      "source": [
        "retriever = DistilBertRetriever().build()\n",
        "\n",
        "mycallback = HardNegativeMiningCallback(all_questions_tokens, all_answers_tokens, \n",
        "                                        answer_question_mapping_index[:1000])\n",
        "\n",
        "for i in range(5):\n",
        "  retriever.fit([train_questions_tokens, train_answers_tokens], train_labels,\n",
        "            validation_data=([valid_questions_tokens,valid_answers_tokens], valid_labels[:1000]),\n",
        "            batch_size=32,\n",
        "            epochs=1,\n",
        "            verbose=1,\n",
        "            callbacks = [mycallback],\n",
        "            shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWZ9PK-TjEYk"
      },
      "source": [
        "### Using mean of sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIjwQk3PiaID",
        "outputId": "de9bcde4-2252-4d0a-a42f-ef298821bc22"
      },
      "source": [
        "retriever = DistilBertRetriever().build()\n",
        "\n",
        "mycallback = HardNegativeMiningCallback(all_questions_tokens, all_answers_tokens, \n",
        "                                        answer_question_mapping_index[:1000])\n",
        "\n",
        "for i in range(5):\n",
        "  retriever.fit([train_questions_tokens, train_answers_tokens], labels,\n",
        "            validation_data=([valid_questions_tokens,valid_answers_tokens], valid_labels[:1000]),\n",
        "            batch_size=32,\n",
        "            epochs=1,\n",
        "            verbose=1,\n",
        "            callbacks = [mycallback],\n",
        "            shuffle = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 80s 2s/step - loss: 0.2832 - val_loss: 0.1751\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:00<00:00, 469.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found: 971 hard negative pairs\n",
            "Train on 1971 samples\n",
            "62/62 [==============================] - 104s 2s/step - loss: 0.1688 - val_loss: 0.1114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:00<00:00, 558.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found: 560 hard negative pairs\n",
            "Train on 2531 samples\n",
            "80/80 [==============================] - 115s 1s/step - loss: 0.1253 - val_loss: 0.1604\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:00<00:00, 607.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found: 417 hard negative pairs\n",
            "Train on 2948 samples\n",
            "93/93 [==============================] - 130s 1s/step - loss: 0.0967 - val_loss: 0.1229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:00<00:00, 520.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found: 286 hard negative pairs\n",
            "Train on 3234 samples\n",
            "102/102 [==============================] - 141s 1s/step - loss: 0.0704 - val_loss: 0.1095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:00<00:00, 476.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found: 194 hard negative pairs\n",
            "Train on 3428 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNv8ss_SqFQq"
      },
      "source": [
        "### Using 2 epochs per hard negative"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3zCRGleqJjx",
        "outputId": "e1f7b1f5-c5fe-43d2-e448-b8929fb9429a"
      },
      "source": [
        "retriever = DistilBertRetriever().build()\n",
        "\n",
        "mycallback = HardNegativeMiningCallback(all_questions_tokens, all_answers_tokens, \n",
        "                                        answer_question_mapping_index[:1000])\n",
        "\n",
        "for i in range(5):\n",
        "  retriever.fit([train_questions_tokens, train_answers_tokens], labels,\n",
        "            validation_data=([valid_questions_tokens,valid_answers_tokens], valid_labels[:1000]),\n",
        "            batch_size=32,\n",
        "            epochs=2,\n",
        "            verbose=1,\n",
        "            callbacks = [mycallback],\n",
        "            shuffle = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "32/32 [==============================] - 80s 2s/step - loss: 0.3465 - val_loss: 0.1824\n",
            "Epoch 2/2\n",
            "32/32 [==============================] - 58s 2s/step - loss: 0.1814 - val_loss: 0.1858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:00<00:00, 555.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found: 966 hard negative pairs\n",
            "Train on 1966 samples\n",
            "Epoch 1/2\n",
            "62/62 [==============================] - 105s 2s/step - loss: 0.2537 - val_loss: 0.1911\n",
            "Epoch 2/2\n",
            "62/62 [==============================] - 94s 2s/step - loss: 0.0972 - val_loss: 0.0922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:00<00:00, 385.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found: 467 hard negative pairs\n",
            "Train on 2433 samples\n",
            "Epoch 1/2\n",
            "77/77 [==============================] - 112s 1s/step - loss: 0.1109 - val_loss: 0.1094\n",
            "Epoch 2/2\n",
            "77/77 [==============================] - 111s 1s/step - loss: 0.0636 - val_loss: 0.0735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:00<00:00, 565.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found: 255 hard negative pairs\n",
            "Train on 2688 samples\n",
            "Epoch 1/2\n",
            "84/84 [==============================] - 120s 1s/step - loss: 0.0647 - val_loss: 0.0917\n",
            "Epoch 2/2\n",
            "84/84 [==============================] - 120s 1s/step - loss: 0.0421 - val_loss: 0.0565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:00<00:00, 564.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found: 132 hard negative pairs\n",
            "Train on 2820 samples\n",
            "Epoch 1/2\n",
            "89/89 [==============================] - 125s 1s/step - loss: 0.0345 - val_loss: 0.0399\n",
            "Epoch 2/2\n",
            "89/89 [==============================] - 125s 1s/step - loss: 0.0241 - val_loss: 0.0293\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:00<00:00, 551.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found: 111 hard negative pairs\n",
            "Train on 2931 samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9XMGjM2z4d4"
      },
      "source": [
        "### Combine all data and train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkFfCPAB2ooA"
      },
      "source": [
        "train_questions_tokens = np.concatenate([train_questions_tokens, covid19_train_questions_tokens])\n",
        "train_answers_tokens = np.concatenate([train_answers_tokens, covid19_train_anwers_tokens])\n",
        "valid_questions_tokens = np.concatenate([valid_questions_tokens, covid19_valid_questions_tokens])\n",
        "valid_answers_tokens = np.concatenate([valid_answers_tokens, covid19_valid_answes_tokens])\n",
        "all_questions_tokens = np.concatenate([all_questions_tokens, covid19_questions_tokens])\n",
        "all_answers_tokens = np.concatenate([all_answers_tokens, covid19_answers_tokens])\n",
        "\n",
        "train_labels = np.concatenate([train_labels, covid19_train_labels])\n",
        "valid_labels = np.concatenate([valid_labels, covid19_valid_labels])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "385aIZlNghQt"
      },
      "source": [
        "np.save(\"/content/drive/MyDrive/all_train_questions_tokens.npy\", train_questions_tokens)\n",
        "np.save(\"/content/drive/MyDrive/all_train_answers_tokens.npy\", train_answers_tokens)\n",
        "np.save(\"/content/drive/MyDrive/all_valid_questions_tokens.npy\", valid_questions_tokens)\n",
        "np.save(\"/content/drive/MyDrive/all_valid_answers_tokens.npy\", valid_answers_tokens)\n",
        "np.save(\"/content/drive/MyDrive/all_all_questions_tokens.npy\", all_questions_tokens)\n",
        "np.save(\"/content/drive/MyDrive/all_all_answers_tokens.npy\", all_answers_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7i7kkxDh1mT"
      },
      "source": [
        "answer_question_mapping_index = np.array(answer_question_mapping_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEkBbHNLh3dO"
      },
      "source": [
        "answer_question_mapping_index = np.concatenate([answer_question_mapping_index, np.arange(200000, 209362)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6yl_c7l0Gkg"
      },
      "source": [
        "n_sample = len(train_answers_tokens)\n",
        "shuffle_indices = random.sample(range(n_sample), n_sample)\n",
        "train_answers_tokens = train_answers_tokens[shuffle_indices]\n",
        "train_questions_tokens = train_questions_tokens[shuffle_indices]\n",
        "train_labels = train_labels[shuffle_indices]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "8ftRmu922m1B",
        "outputId": "47019cc3-aa0c-456c-f2ca-744732c3194c"
      },
      "source": [
        "retriever = DistilBertRetriever().build()\n",
        "\n",
        "mycallback = HardNegativeMiningCallback(all_questions_tokens, all_answers_tokens, \n",
        "                                        answer_question_mapping_index)\n",
        "\n",
        "for i in range(5):\n",
        "  retriever.fit([train_questions_tokens, train_answers_tokens], train_labels,\n",
        "            validation_data=([valid_questions_tokens,valid_answers_tokens], valid_labels),\n",
        "            batch_size=64,\n",
        "            epochs=2,\n",
        "            verbose=1,\n",
        "            callbacks = [mycallback],\n",
        "            shuffle = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            " 724/8376 [=>............................] - ETA: 5:01:46 - loss: 0.0834"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-180-c235be906ab6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmycallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             shuffle = False)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTi7dJip3Acg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}