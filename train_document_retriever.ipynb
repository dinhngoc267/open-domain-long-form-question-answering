{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train document retriever.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "469d74c73a0e435cb7dc2e5bc213a156": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5a939b851c0348a0aa9374e09e33fb4e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_91da7cb912dc497aa769441ec311ad76",
              "IPY_MODEL_4be6abf6873942d894d943969550c056",
              "IPY_MODEL_262c7536b7fd4f39b851fe52f0525308"
            ]
          }
        },
        "5a939b851c0348a0aa9374e09e33fb4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91da7cb912dc497aa769441ec311ad76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dc88cd3a14634c48b338f8e222a93d64",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c143bb3364e411daa78fff0017aa9df"
          }
        },
        "4be6abf6873942d894d943969550c056": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f48fc29308a74fcfb691878434cbf42f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 17848,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 17848,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d676212cb93d4c2db49b090c61d10e98"
          }
        },
        "262c7536b7fd4f39b851fe52f0525308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_636df9db9e7f4a408c68f9bba265a10e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 17.8k/17.8k [00:00&lt;00:00, 5.65kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ec83d89cb766426e9d8d2ea4bc2db883"
          }
        },
        "dc88cd3a14634c48b338f8e222a93d64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c143bb3364e411daa78fff0017aa9df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f48fc29308a74fcfb691878434cbf42f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d676212cb93d4c2db49b090c61d10e98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "636df9db9e7f4a408c68f9bba265a10e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ec83d89cb766426e9d8d2ea4bc2db883": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "663057afea97417abd53355b66c3fe73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f95c3bf96702401f92fab0c3defd6d49",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_886810825cc541a29ed3ab0283e8d5fe",
              "IPY_MODEL_add2d36f57a8466a9498a1ed4bf96b1a",
              "IPY_MODEL_ad67d7727071438fa15a48a0488f74bc"
            ]
          }
        },
        "f95c3bf96702401f92fab0c3defd6d49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "886810825cc541a29ed3ab0283e8d5fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b38b7f1d7d2047f39a14503afc838ce4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b5f31eaa22654503880a63aa9ca79350"
          }
        },
        "add2d36f57a8466a9498a1ed4bf96b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6a7b64b5575643d7bdc48f1fb6b39fa6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 483,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 483,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_284e86bc92504df7ada8dad0e5eb17ef"
          }
        },
        "ad67d7727071438fa15a48a0488f74bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8c66423f37cf4a03a3bff75454ab2e10",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 483/483 [00:00&lt;00:00, 17.9kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b69a727e89714fb391505821e1827abe"
          }
        },
        "b38b7f1d7d2047f39a14503afc838ce4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b5f31eaa22654503880a63aa9ca79350": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a7b64b5575643d7bdc48f1fb6b39fa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "284e86bc92504df7ada8dad0e5eb17ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8c66423f37cf4a03a3bff75454ab2e10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b69a727e89714fb391505821e1827abe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m18s6GAbk-Qa",
        "outputId": "993b82e9-5d16-417f-874f-d0c579f39b2b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMo073RhIy4v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d98d5e7-c6a9-482f-c4b3-8a033f434215"
      },
      "source": [
        "!pip install -qq transformers\n",
        "!pip install -qq nlp"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.9 MB 2.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 636 kB 64.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 82.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 63.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 6.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 3.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 243 kB 55.1 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiRimxQN8Mbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456,
          "referenced_widgets": [
            "469d74c73a0e435cb7dc2e5bc213a156",
            "5a939b851c0348a0aa9374e09e33fb4e",
            "91da7cb912dc497aa769441ec311ad76",
            "4be6abf6873942d894d943969550c056",
            "262c7536b7fd4f39b851fe52f0525308",
            "dc88cd3a14634c48b338f8e222a93d64",
            "2c143bb3364e411daa78fff0017aa9df",
            "f48fc29308a74fcfb691878434cbf42f",
            "d676212cb93d4c2db49b090c61d10e98",
            "636df9db9e7f4a408c68f9bba265a10e",
            "ec83d89cb766426e9d8d2ea4bc2db883"
          ]
        },
        "outputId": "30ca1565-8aec-4d2c-e4eb-8ebdb855a443"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import transformers\n",
        "from tqdm import tqdm\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow as tf\n",
        "from keras.layers import Lambda\n",
        "import nlp\n",
        "import keras\n",
        "import string\n",
        "import math\n",
        "import random\n",
        "\n",
        "eli5 = nlp.load_dataset('eli5')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "469d74c73a0e435cb7dc2e5bc213a156",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/17.8k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c89d34952c74b3a99188436d10ea5c9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/3.71k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset eli5/LFQA_reddit (download: 6.03 MiB, generated: 1.26 GiB, post-processed: Unknown sizetotal: 1.26 GiB) to /root/.cache/huggingface/datasets/eli5/LFQA_reddit/1.0.0/58e61a99404336f0891b4457a02232489b50131bdca9c1691054aeee2f6f1a6e...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "781380fd7ba6470eaee1234e8bccd673",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/3.50k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5394b6e640594173a1db5d024642cc7c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/576M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "767a575cf44e4fbe9666170ab6b8a3f9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/21.1M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85bf15ffd79242fa97941856d738eec0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/53.0M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "451fe665825e4c1392b72689cd0c5bc1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/286M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8d35ac8b79b4c1cb5b0ad0667af3dcc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/9.65M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cebecb50dfc7462a875bde5b0160548a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/17.7M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa6bf20fa9954ab290d6241c3279e7eb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/330M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6cee6a5c8c044bfa84e657c98de6005d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/18.7M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14ca4587841e405db3ef90638f79cb94",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/36.2M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset eli5 downloaded and prepared to /root/.cache/huggingface/datasets/eli5/LFQA_reddit/1.0.0/58e61a99404336f0891b4457a02232489b50131bdca9c1691054aeee2f6f1a6e. Subsequent calls will reuse this data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_oLPhxG4tzW"
      },
      "source": [
        "#### Handle Eli5 dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sB6kpk05Sub"
      },
      "source": [
        "> After observing: There are some answers are not relevant to the questions and there are some questions are too short (one or two words)\n",
        "\n",
        "> I just get the questions which have more than two words\n",
        "> Just get maximum 2 answers with highest score each question.\n",
        "> Just get answer which more than 6 words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsQbwwBiPGAt"
      },
      "source": [
        "> After cleaning and check validation\n",
        "\n",
        "- Number of all questions: 263186\n",
        "- Number of all answes: 425285\n",
        "- Number of training questions: 688469\n",
        "- Number of training answers: 688469\n",
        "\n",
        "> Too large to train. It takes 6-7 hours per epoch\n",
        "\n",
        "> I cut off to 200,000 questions by random sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AzIdsHN6xPt"
      },
      "source": [
        "def is_valid_question(text):\n",
        "  if len(text.split()) > 3:\n",
        "    return True  \n",
        "  if len(text.split()) == 3:\n",
        "    if ('?' in text) or (text[0].lower() in ['w', 'h', 'i', 'a', 'd']):\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "def is_valid_answer(text):\n",
        "  if len(text.split()) > 8:\n",
        "    return True\n",
        "  return False\n",
        "\n",
        "def clean_text(text):\n",
        "  text = text.replace(\"\\n\",\"\")\n",
        "  text = ' '.join([x for x in text.split() if x != \"\" and x not in string.punctuation and \"URL\" not in x and \"@\" not in x and \"www\" not in x])\n",
        "  return text\n",
        "\n",
        "def create_eli5_q_a_dict(data, n_samples = None):\n",
        "  list_dict = []\n",
        "\n",
        "  for idx in tqdm(range(len(data))):\n",
        "    item = data[idx]\n",
        "    q_a = {}\n",
        "    \n",
        "    q_a['question'] = clean_text(item['title'])\n",
        "    if is_valid_question(q_a['question']) == False:\n",
        "      continue\n",
        "    \n",
        "    q_a['answers'] = []\n",
        "\n",
        "    for ans in item['answers']['text']:\n",
        "      tmp = clean_text(ans)\n",
        "      if is_valid_answer(tmp) == True:\n",
        "        q_a['answers'].append(tmp)\n",
        "        if len(q_a['answers']) == 2:\n",
        "          break\n",
        "\n",
        "    if len(q_a['answers']) > 0:\n",
        "      list_dict.append(q_a)\n",
        "\n",
        "  if n_samples is not None:\n",
        "    shuffle_indices = random.sample(range(len(list_dict)), n_samples)\n",
        "    list_dict = np.array(list_dict)\n",
        "    list_dict = list_dict[shuffle_indices]\n",
        "\n",
        "  return list_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rK_khs9x_Cce",
        "outputId": "3ad35a11-77d0-4df8-d32b-61ce995cc1aa"
      },
      "source": [
        "eli5_q_a_training_dict = create_eli5_q_a_dict(eli5['train_eli5'], n_samples=200000)\n",
        "eli5_q_a_valid_dict = create_eli5_q_a_dict(eli5['validation_eli5'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 272634/272634 [00:48<00:00, 5571.88it/s]\n",
            "100%|██████████| 9812/9812 [00:01<00:00, 5766.37it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Y0mj2QFp_gi"
      },
      "source": [
        "#### Handle FQA Covid 19 dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7qQToCeqJTM"
      },
      "source": [
        "import pandas as pd\n",
        "covid19_df1 = pd.read_csv(\"/content/drive/MyDrive/FAQ_Bank.csv\")\n",
        "covid19_df1.dropna(inplace=True)\n",
        "\n",
        "covid19_questions_data1 = covid19_df1[covid19_df1['language'] == 'en']['question'].apply(lambda x: clean_text(x))\n",
        "covid19_answers_data1 = covid19_df1[covid19_df1['language'] == 'en']['answer'].apply(lambda x: clean_text(x))\n",
        "covid19_questions_data1 = covid19_questions_data1.values\n",
        "covid19_answers_data1 = covid19_answers_data1.values\n",
        "\n",
        "covid19_df2 = pd.read_csv(\"/content/drive/MyDrive/faq_covidbert.csv\")\n",
        "\n",
        "covid19_questions_data2 = covid19_df2[covid19_df2['lang']=='en']['question'].apply(lambda x: clean_text(x))\n",
        "covid19_answers_data2 = covid19_df2[covid19_df2['lang']=='en']['answer'].apply(lambda x: clean_text(x))\n",
        "covid19_questions_data2 = covid19_questions_data2.values\n",
        "covid19_answers_data2 = covid19_answers_data2.values\n",
        "\n",
        "covid19_questions = np.concatenate([covid19_questions_data1, covid19_questions_data2])\n",
        "covid19_answers = np.concatenate([covid19_answers_data1, covid19_answers_data2])\n",
        "\n",
        "n_samples = len(covid19_questions)\n",
        "shuffle_indices = random.sample(range(n_samples), n_samples)\n",
        "\n",
        "covid19_questions = covid19_questions[shuffle_indices]\n",
        "covid19_answers = covid19_answers[shuffle_indices]\n",
        "\n",
        "covid19_train_questions = covid19_questions[:8000]\n",
        "covid19_train_anwers = covid19_answers[:8000]\n",
        "\n",
        "covid19_vali_questions = covid19_questions[8000:]\n",
        "covid19_valid_answes = covid19_answers[8000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBZrifjgEOR-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b7f877c-4121-420a-d9ee-6f1f0f6fbacd"
      },
      "source": [
        "def create_covid19_q_a_dict(covid19_questions, covid19_answers):\n",
        "  list_dict = []\n",
        "\n",
        "  for idx in range(len(covid19_questions)):\n",
        "    q_a_dict = {}\n",
        "    q_a_dict['question'] = covid19_questions[idx]\n",
        "    q_a_dict['answers'] = [covid19_answers[idx]]\n",
        "\n",
        "    list_dict.append(q_a_dict)\n",
        "  \n",
        "  return np.array(list_dict)\n",
        "\n",
        "covid19_train_q_a_dict = create_covid19_q_a_dict(covid19_train_questions, covid19_train_anwers)\n",
        "covid19_valid_q_a_dict = create_covid19_q_a_dict(covid19_vali_questions, covid19_valid_answes)\n",
        "print('Number of questions in train set:', len(covid19_train_q_a_dict))\n",
        "print('Number of questions in valid set:', len(covid19_valid_q_a_dict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of questions in train set: 8000\n",
            "Number of questions in valid set: 1362\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6yB7CXgH6QC"
      },
      "source": [
        "#### Combine two datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4at2EgIH99K",
        "outputId": "3dc31fda-26fb-451f-f678-4838e651a181"
      },
      "source": [
        "q_a_training_dict = np.concatenate([eli5_q_a_training_dict, covid19_train_q_a_dict])\n",
        "q_a_valid_dict = np.concatenate([eli5_q_a_valid_dict, covid19_valid_q_a_dict])\n",
        "\n",
        "# after concat, shuffle data:\n",
        "\n",
        "n_samples = len(q_a_training_dict)\n",
        "shuffle_indices = random.sample(range(n_samples), n_samples)\n",
        "q_a_training_dict = q_a_training_dict[shuffle_indices]\n",
        "\n",
        "n_samples = len(q_a_valid_dict)\n",
        "shuffle_indices = random.sample(range(n_samples), n_samples)\n",
        "q_a_valid_dict = q_a_valid_dict[shuffle_indices]\n",
        "\n",
        "print('Length of training dict', len(q_a_training_dict))\n",
        "print('Length of valid dict', len(q_a_valid_dict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of training dict 208000\n",
            "Length of valid dict 10934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-lSavu4I0ja"
      },
      "source": [
        "def create_all_training_q_a_list(data): \n",
        "  all_questions = []\n",
        "  all_answers = []\n",
        "  answer_question_mapping_index = []\n",
        "\n",
        "  for idx in tqdm(range(len(data))):\n",
        "    item = data[idx]\n",
        "    \n",
        "    all_questions.append(item['question'])  \n",
        "    for ans in item['answers']:\n",
        "      all_answers.append(ans)\n",
        "      answer_question_mapping_index.append(idx)\n",
        "\n",
        "  return all_questions, all_answers, answer_question_mapping_index\n",
        "\n",
        "def create_pairs_dataset(data):\n",
        "  questions = []\n",
        "  answers = []\n",
        "\n",
        "  # 1: positive, 0: negative\n",
        "  labels = []\n",
        "\n",
        "  for idx in tqdm(range(len(data))):\n",
        "    item = data[idx]\n",
        "    for ans in item['answers']:\n",
        "      questions.append(item['question'])\n",
        "      answers.append(ans)\n",
        "      labels.append(1)\n",
        "    \n",
        "    neg_idx = np.random.randint(0, len(data),1)[0]\n",
        "    if neg_idx != idx:\n",
        "      questions.append(item['question'])\n",
        "      answers.append(data[neg_idx]['answers'][0])\n",
        "      labels.append(0)\n",
        "\n",
        "  return questions, answers, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_8h_4PlJs28",
        "outputId": "44e472ec-e4d1-446a-f9a4-13b6a443282c"
      },
      "source": [
        "all_questions, all_answers, answer_question_mapping_index = create_all_training_q_a_list(q_a_training_dict[:500])\n",
        "train_questions, train_answers, train_labels = create_pairs_dataset(q_a_training_dict[:500])\n",
        "valid_questions, valid_answers, valid_labels = create_pairs_dataset(q_a_valid_dict[:100])\n",
        "\n",
        "print('Number of all questions:',len(all_questions))\n",
        "print('Number of all answes:',len(all_answers))\n",
        "print('Number of training questions:', len(train_questions))\n",
        "print('Number of training answers:', len(train_answers))\n",
        "\n",
        "train_labels = np.array(train_labels)\n",
        "valid_labels = np.array(valid_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:00<00:00, 370521.55it/s]\n",
            "100%|██████████| 500/500 [00:00<00:00, 51492.92it/s]\n",
            "100%|██████████| 100/100 [00:00<00:00, 56527.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of all questions: 500\n",
            "Number of all answes: 824\n",
            "Number of training questions: 1323\n",
            "Number of training answers: 1323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285,
          "referenced_widgets": [
            "663057afea97417abd53355b66c3fe73",
            "f95c3bf96702401f92fab0c3defd6d49",
            "886810825cc541a29ed3ab0283e8d5fe",
            "add2d36f57a8466a9498a1ed4bf96b1a",
            "ad67d7727071438fa15a48a0488f74bc",
            "b38b7f1d7d2047f39a14503afc838ce4",
            "b5f31eaa22654503880a63aa9ca79350",
            "6a7b64b5575643d7bdc48f1fb6b39fa6",
            "284e86bc92504df7ada8dad0e5eb17ef",
            "8c66423f37cf4a03a3bff75454ab2e10",
            "b69a727e89714fb391505821e1827abe"
          ]
        },
        "id": "yJiOy7RaH0qf",
        "outputId": "d9969bea-f368-4f88-9296-7e031faced62"
      },
      "source": [
        "transformer_layer = transformers.TFDistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "663057afea97417abd53355b66c3fe73",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0e5ed5dca9b4a0f875a3bad5a2ec554",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/347M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['activation_13', 'vocab_transform', 'vocab_projector', 'vocab_layer_norm']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "191633ab0c1a4edc95eabb3195763b81",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f1641d466c54ba385979075598341b9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d9357819fb3b41be80d7f6e849fcefc2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dPSiFMRDPYf"
      },
      "source": [
        "def bert_encode(texts, tokenizer, max_len=512):\n",
        "  all_tokens = []\n",
        "\n",
        "  for idx in tqdm(range(len(texts))):\n",
        "    text = texts[idx]\n",
        "\n",
        "    text = ' '.join([x for x in text.split()[:100]])\n",
        "    text = tokenizer.tokenize(text)\n",
        "    text = text[:max_len-2]\n",
        "    input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
        "\n",
        "    pad_len = max_len - len(input_sequence)\n",
        "    tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
        "    tokens += [0]*pad_len\n",
        "    all_tokens.append(tokens)\n",
        "\n",
        "  return np.array(all_tokens)\n",
        "\n",
        "def build_siamese_model(transformer, max_len=512, embedding_dims = 128):\n",
        "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "    sequence_output = transformer(input_word_ids)[0]\n",
        "\n",
        "    #out = sequence_output[:, 0, :]\n",
        "    out = tf.reduce_mean(sequence_output, axis=1)\n",
        "    out = Dense(128, activation = 'relu')(out)\n",
        "    \n",
        "    model = Model(inputs=input_word_ids, outputs=out)    \n",
        "    return model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZKyHDVza5yL"
      },
      "source": [
        "class HardNegativeMiningCallback(keras.callbacks.Callback):\n",
        "  def __init__(self, all_question_tokens, all_answer_tokens, answer_question_mapping_index):\n",
        "    self.all_question_tokens = all_question_tokens\n",
        "    self.all_answer_tokens = all_answer_tokens\n",
        "    self.answer_question_mapping_index = np.array(answer_question_mapping_index)\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    if epoch ==1:\n",
        "      question_embeddings = self.model.layers[2].predict(self.all_question_tokens[:512], batch_size = 512)\n",
        "      answer_embeddings = self.model.layers[2].predict(self.all_answer_tokens[:512], batch_size = 512)\n",
        "\n",
        "      for i in tqdm(range(512, len(self.all_question_tokens), 512)):\n",
        "        batch_question_embeddings = self.model.layers[2].predict(self.all_question_tokens[i:i+512], batch_size = 512)\n",
        "        question_embeddings = tf.concat([question_embeddings, batch_question_embeddings], axis=0)\n",
        "\n",
        "      for i in tqdm(range(512, len(self.all_answer_tokens), 512)):\n",
        "        batch_answer_embeddings = self.model.layers[2].predict(self.all_answer_tokens[i:i+512], batch_size = 512)\n",
        "        answer_embeddings = tf.concat([answer_embeddings, batch_answer_embeddings], axis=0)\n",
        "\n",
        "      dist_matrix = tf.reduce_sum((tf.expand_dims(answer_embeddings[:5], 1)-tf.expand_dims(question_embeddings, 0))**2,2)\n",
        "      min_dist_indices = tf.argmin(dist_matrix, axis=1)\n",
        "\n",
        "      for i in tqdm(range(5, answer_embeddings.shape[0], 5)):\n",
        "        tmp = tf.reduce_sum((tf.expand_dims(answer_embeddings[i:i+5], 1)-tf.expand_dims(question_embeddings, 0))**2,2)\n",
        "        tmp_min_dist_indices = tf.argmin(tmp, axis=1)\n",
        "        min_dist_indices = tf.concat([min_dist_indices, tmp_min_dist_indices], axis=0)\n",
        "\n",
        "      min_dist_indices = keras.backend.eval(min_dist_indices)\n",
        "      hard_negative_indices = (min_dist_indices != self.answer_question_mapping_index).nonzero()[0]\n",
        "      hard_negative_pairs = [[i, min_dist_indices[i]] for i in hard_negative_indices]\n",
        "      hard_negative_pairs = np.array(hard_negative_pairs)\n",
        "\n",
        "      print('\\nFound: {} hard negative pairs'.format(len(hard_negative_pairs)))\n",
        "\n",
        "      hard_negative_question_tokens = self.all_question_tokens[hard_negative_pairs[:,1]]\n",
        "      hard_negative_answer_tokens = self.all_answer_tokens[hard_negative_pairs[:,0]]\n",
        "\n",
        "      global train_questions_tokens\n",
        "      global train_answers_tokens\n",
        "      global train_labels\n",
        "      train_questions_tokens = np.concatenate([train_questions_tokens, hard_negative_question_tokens], axis=0)\n",
        "      train_answers_tokens = np.concatenate([train_answers_tokens, hard_negative_answer_tokens], axis=0)\n",
        "      train_labels = np.concatenate([train_labels, np.zeros(shape=(len(hard_negative_pairs)))])\n",
        "\n",
        "      # shuffle_indices = random.sample(range(len(labels)), len(labels))\n",
        "      # train_answers_tokens = train_answers_tokens[shuffle_indices]\n",
        "      # train_questions_tokens = train_questions_tokens[shuffle_indices]\n",
        "      # train_labels = train_labels[shuffle_indices] \n",
        "\n",
        "      print('Train on {} samples'.format(len(train_questions_tokens)))\n",
        "\n",
        "class DistilBertRetriever():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  \n",
        "  def euclidean_distance(self, vectors):\n",
        "    featsA, featsB = vectors\n",
        "    # compute the sum of squared distances between the vectors\n",
        "    sumSquared = K.sum(K.square(featsA - featsB), axis=1,keepdims=True)\n",
        "    # return the euclidean distance between the vectors\n",
        "    return K.sqrt(K.maximum(sumSquared, K.epsilon()))\n",
        "\n",
        "  def cosine_distance(self, vectors):\n",
        "    x, y = vectors\n",
        "    x = K.l2_normalize(x, axis=1)\n",
        "    y = K.l2_normalize(y, axis=1)\n",
        "    return 1 - abs(tf.losses.cosine_similarity(x, y, axis=1))\n",
        "    #return -K.mean(x * y, axis=1, keepdims=True)\n",
        "\n",
        "  def contrastive_loss(self, y, preds, margin=1):\n",
        "    # explicitly cast the true class label data type to the predicted\n",
        "    # class label data type (otherwise we run the risk of having two\n",
        "    # separate data types, causing TensorFlow to error out)\n",
        "    y = tf.cast(y, preds.dtype)\n",
        "    # calculate the contrastive loss between the true labels and\n",
        "    # the predicted labels\n",
        "    squaredPreds = K.square(preds)\n",
        "    squaredMargin = K.square(K.maximum(margin - preds, 0))\n",
        "    loss = K.mean(y * squaredPreds + (1 - y) * squaredMargin)\n",
        "    # return the computed contrastive loss to the calling function\n",
        "    return loss\n",
        "\n",
        "  def build(self):\n",
        "    A = Input(shape=100)\n",
        "    B = Input(shape=100)\n",
        "    featureExtractor = build_siamese_model(transformer_layer, max_len=100)\n",
        "    featsA = featureExtractor(A)\n",
        "    featsB = featureExtractor(B)\n",
        "    # finally, construct the siamese network\n",
        "    distance = Lambda(self.euclidean_distance)([featsA, featsB])\n",
        "    model = Model(inputs=[A, B], outputs=distance)\n",
        "    model.compile(loss=self.contrastive_loss, optimizer=Adam(learning_rate=0.00003))\n",
        "    return model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INRyjWYrWj6U",
        "outputId": "211829e2-c1c5-434f-b394-736fea7f5861"
      },
      "source": [
        "train_questions_tokens = bert_encode(train_questions, tokenizer, max_len=100)\n",
        "train_answers_tokens = bert_encode(train_answers, tokenizer, max_len=100)\n",
        "\n",
        "valid_questions_tokens = bert_encode(valid_questions, tokenizer, max_len=100)\n",
        "valid_answers_tokens = bert_encode(valid_answers, tokenizer, max_len=100)\n",
        "\n",
        "all_questions_tokens = bert_encode(all_questions, tokenizer, max_len=100)\n",
        "all_answers_tokens = bert_encode(all_answers, tokenizer, max_len=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1323/1323 [00:00<00:00, 2577.76it/s]\n",
            "100%|██████████| 1323/1323 [00:02<00:00, 555.32it/s]\n",
            "100%|██████████| 256/256 [00:00<00:00, 1833.06it/s]\n",
            "100%|██████████| 256/256 [00:00<00:00, 583.82it/s]\n",
            "100%|██████████| 500/500 [00:00<00:00, 2539.09it/s]\n",
            "100%|██████████| 824/824 [00:01<00:00, 566.03it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaAdN4MGFFjG"
      },
      "source": [
        "## Load tokens and train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OipmKVOvwCh3"
      },
      "source": [
        "train_questions_tokens = np.load(\"/content/drive/MyDrive/train_questions_tokens.npy\")\n",
        "train_answers_tokens = np.load(\"/content/drive/MyDrive/train_answers_tokens.npy\")\n",
        "valid_questions_tokens = np.load(\"/content/drive/MyDrive/valid_questions_tokens.npy\")\n",
        "valid_answers_tokens = np.load(\"/content/drive/MyDrive/valid_answers_tokens.npy\")\n",
        "all_questions_tokens = np.load(\"/content/drive/MyDrive/all_questions_tokens.npy\")\n",
        "all_answers_tokens = np.load(\"/content/drive/MyDrive/all_answers_tokens.npy\")\n",
        "train_labels = np.load(\"/content/drive/MyDrive/train_labels.npy\")\n",
        "valid_labels = np.load(\"/content/drive/MyDrive/valid_labels.npy\")\n",
        "answer_question_mapping_index = np.load(\"/content/drive/MyDrive/answer_question_mapping_index.npy\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9dn0ZUPPpJU"
      },
      "source": [
        "n_samples = len(train_questions_tokens)\n",
        "shuffle_indices = random.sample(range(n_samples), n_samples)\n",
        "train_answers_tokens = train_answers_tokens[shuffle_indices]\n",
        "train_questions_tokens = train_questions_tokens[shuffle_indices]\n",
        "train_labels = train_labels[shuffle_indices] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufox5YQMjB6O"
      },
      "source": [
        "### Using cls token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtOovfUJH0cC",
        "outputId": "3271494b-28e7-44d3-b46d-230d85b1feb5"
      },
      "source": [
        "len(all_answers_tokens)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "331119"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrnkrFqnGrsN"
      },
      "source": [
        "retriever = DistilBertRetriever().build()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xd62jl5-B7u7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d7112b8-2f87-4155-ec20-7dc88fd0d7d9"
      },
      "source": [
        "retriever = DistilBertRetriever().build()\n",
        "\n",
        "mycallback = HardNegativeMiningCallback(all_questions_tokens, \n",
        "                                        all_answers_tokens, \n",
        "                                        answer_question_mapping_index)\n",
        "\n",
        "for i in range(5):\n",
        "  retriever.fit([train_questions_tokens, train_answers_tokens], train_labels,\n",
        "            validation_data=([valid_questions_tokens,valid_answers_tokens], valid_labels),\n",
        "            batch_size=32,\n",
        "            epochs=2,\n",
        "            verbose=1,\n",
        "            callbacks = [mycallback],\n",
        "            shuffle = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "  688/16848 [>.............................] - ETA: 1:36:46 - loss: 0.1305"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWZ9PK-TjEYk"
      },
      "source": [
        "### Using mean of sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIjwQk3PiaID",
        "outputId": "8894a10f-543b-429f-f284-854774c1081a"
      },
      "source": [
        "retriever = DistilBertRetriever().build()\n",
        "\n",
        "mycallback = HardNegativeMiningCallback(all_questions_tokens, all_answers_tokens, \n",
        "                                        answer_question_mapping_index)\n",
        "\n",
        "for i in range(3):\n",
        "  retriever.fit([train_questions_tokens, train_answers_tokens], train_labels,\n",
        "            validation_data=([valid_questions_tokens,valid_answers_tokens], valid_labels),\n",
        "            batch_size=32,\n",
        "            epochs=1,\n",
        "            verbose=1,\n",
        "            callbacks = [mycallback],\n",
        "            shuffle = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162/162 [==============================] - 78s 409ms/step - loss: 0.2534 - val_loss: 0.1207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:03<00:00,  1.21s/it]\n",
            "100%|██████████| 6/6 [00:04<00:00,  1.37it/s]\n",
            "100%|██████████| 633/633 [00:00<00:00, 3197.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found: 2445 hard negative pairs\n",
            "Train on 7613 samples\n",
            "238/238 [==============================] - 97s 378ms/step - loss: 0.1903 - val_loss: 0.1752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:02<00:00,  1.22it/s]\n",
            "100%|██████████| 6/6 [00:04<00:00,  1.37it/s]\n",
            "100%|██████████| 633/633 [00:00<00:00, 3264.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found: 1451 hard negative pairs\n",
            "Train on 9064 samples\n",
            "284/284 [==============================] - 106s 374ms/step - loss: 0.1556 - val_loss: 0.2109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:02<00:00,  1.22it/s]\n",
            "100%|██████████| 6/6 [00:04<00:00,  1.37it/s]\n",
            "100%|██████████| 633/633 [00:00<00:00, 3231.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found: 994 hard negative pairs\n",
            "Train on 10058 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNv8ss_SqFQq"
      },
      "source": [
        "### Using 2 epochs per hard negative"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3zCRGleqJjx",
        "outputId": "31604e06-1185-4649-f9c1-fc8ad458ec86"
      },
      "source": [
        "retriever = DistilBertRetriever().build()\n",
        "\n",
        "mycallback = HardNegativeMiningCallback(all_questions_tokens, all_answers_tokens, \n",
        "                                        answer_question_mapping_index)\n",
        "\n",
        "for i in range(3):\n",
        "  retriever.fit([train_questions_tokens, train_answers_tokens], train_labels,\n",
        "            validation_data=([valid_questions_tokens,valid_answers_tokens], valid_labels),\n",
        "            batch_size=32,\n",
        "            epochs=2,\n",
        "            verbose=1,\n",
        "            callbacks = [mycallback],\n",
        "            shuffle = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "162/162 [==============================] - 77s 400ms/step - loss: 0.2829 - val_loss: 0.1509\n",
            "Epoch 2/2\n",
            "162/162 [==============================] - 62s 386ms/step - loss: 0.1108 - val_loss: 0.1107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:03<00:00,  1.19s/it]\n",
            "100%|██████████| 6/6 [00:04<00:00,  1.37it/s]\n",
            "100%|██████████| 633/633 [00:00<00:00, 3328.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found: 2038 hard negative pairs\n",
            "Train on 7203 samples\n",
            "Epoch 1/2\n",
            "226/226 [==============================] - 93s 378ms/step - loss: 0.0598 - val_loss: 37.9965\n",
            "Epoch 2/2\n",
            "226/226 [==============================] - 85s 378ms/step - loss: 0.4143 - val_loss: 0.2830\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:02<00:00,  1.22it/s]\n",
            "100%|██████████| 6/6 [00:04<00:00,  1.37it/s]\n",
            "100%|██████████| 633/633 [00:00<00:00, 3227.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found: 3166 hard negative pairs\n",
            "Train on 10369 samples\n",
            "Epoch 1/2\n",
            "325/325 [==============================] - 121s 372ms/step - loss: 0.1386 - val_loss: 13.6113\n",
            "Epoch 2/2\n",
            "325/325 [==============================] - 121s 372ms/step - loss: 0.1848 - val_loss: 30.2989\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:02<00:00,  1.22it/s]\n",
            "100%|██████████| 6/6 [00:04<00:00,  1.37it/s]\n",
            "100%|██████████| 633/633 [00:00<00:00, 3287.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found: 3164 hard negative pairs\n",
            "Train on 13533 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SBKSESbk97G"
      },
      "source": [
        "### Using cosine distance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTi7dJip3Acg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "outputId": "afe7f286-6a2e-4ae0-f00e-2c947262f64e"
      },
      "source": [
        "retriever = DistilBertRetriever().build()\n",
        "\n",
        "mycallback = HardNegativeMiningCallback(all_questions_tokens, all_answers_tokens, \n",
        "                                        answer_question_mapping_index)\n",
        "\n",
        "for i in range(3):\n",
        "  retriever.fit([train_questions_tokens, train_answers_tokens], train_labels,\n",
        "            validation_data=([valid_questions_tokens,valid_answers_tokens], valid_labels),\n",
        "            batch_size=32,\n",
        "            epochs=2,\n",
        "            verbose=1,\n",
        "            callbacks = [mycallback],\n",
        "            shuffle = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "162/162 [==============================] - 131s 735ms/step - loss: 0.2603 - val_loss: 0.2473\n",
            "Epoch 2/2\n",
            "162/162 [==============================] - 63s 387ms/step - loss: 0.2554 - val_loss: 0.2748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:03<00:00,  1.21s/it]\n",
            "100%|██████████| 6/6 [00:04<00:00,  1.37it/s]\n",
            "100%|██████████| 633/633 [00:00<00:00, 3045.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found: 3168 hard negative pairs\n",
            "Train on 8336 samples\n",
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2559\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2560\u001b[0;31m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2561\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Operation 'model_26/model_25/tf_distil_bert_model_7/distilbert/transformer/layer_._4/attention/v_lin/Tensordot/concat/axis' has no attr named '_read_only_resource_inputs'.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-2e9c65e742a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmycallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             shuffle = True)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3036\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m-> 3038\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3458\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m   3459\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[0;32m-> 3460\u001b[0;31m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3381\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3382\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3383\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         if x is not None)\n\u001b[1;32m   1047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m     \u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0madd_control_dependencies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/auto_control_deps.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, unused_type, unused_value, unused_traceback)\u001b[0m\n\u001b[1;32m    413\u001b[0m       \u001b[0;31m# Check for any resource inputs. If we find any, we update control_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m       \u001b[0;31m# and last_write_to_resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_get_resource_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0mis_read\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresource_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mResourceType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_ONLY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0minput_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/auto_control_deps.py\u001b[0m in \u001b[0;36m_get_resource_inputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_resource_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;34m\"\"\"Returns an iterable of resources touched by this `op`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m   \u001b[0mreads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrites\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_read_write_resource_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m   \u001b[0msaturated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msaturated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/auto_control_deps_utils.py\u001b[0m in \u001b[0;36mget_read_write_resource_inputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mread_only_input_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mREAD_ONLY_RESOURCE_INPUTS_ATTR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;31m# Attr was not set. Add all resource inputs to `writes` and return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2558\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2559\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2560\u001b[0;31m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2561\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2562\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "rafOOVJMqoto",
        "outputId": "555b0060-2310-4472-ba17-407231c2bf46"
      },
      "source": [
        "question_embeddings = retriever.layers[2].predict(all_questions_tokens[:512], batch_size = 512)\n",
        "answer_embeddings = retriever.layers[2].predict(all_answers_tokens[:512], batch_size = 512)\n",
        "\n",
        "for i in tqdm(range(512, len(all_questions_tokens), 512)):\n",
        "  batch_question_embeddings = retriever.layers[2].predict(all_questions_tokens[i:i+512], batch_size = 512)\n",
        "  question_embeddings = tf.concat([question_embeddings, batch_question_embeddings], axis=0)\n",
        "\n",
        "for i in tqdm(range(512, len(all_answers_tokens), 512)):\n",
        "  batch_answer_embeddings = retriever.layers[2].predict(all_answers_tokens[i:i+512], batch_size = 512)\n",
        "  answer_embeddings = tf.concat([answer_embeddings, batch_answer_embeddings], axis=0)\n",
        "\n",
        "dist_matrix = tf.reduce_sum((tf.expand_dims(answer_embeddings[:5], 1)-tf.expand_dims(question_embeddings, 0))**2,2)\n",
        "\n",
        "for i in tqdm(range(5, answer_embeddings.shape[0], 5)):\n",
        "  tmp = tf.reduce_sum((tf.expand_dims(answer_embeddings[i:i+5], 1)-tf.expand_dims(question_embeddings, 0))**2,2)\n",
        "  dist_matrix = tf.concat([dist_matrix, tmp], axis=0)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 406/406 [05:38<00:00,  1.20it/s]\n",
            "100%|██████████| 646/646 [08:59<00:00,  1.20it/s]\n",
            "  2%|▏         | 1032/66223 [00:23<25:01, 43.40it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-affe2aeede09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mdist_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdist_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1767\u001b[0m           dtype=dtypes.int32).get_shape().assert_has_rank(0)\n\u001b[1;32m   1768\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1769\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1211\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6940\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6941\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6942\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[5170,208000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:ConcatV2] name: concat"
          ]
        }
      ]
    }
  ]
}